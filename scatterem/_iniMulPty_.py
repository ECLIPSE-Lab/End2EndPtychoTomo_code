# __version__ = "0.0.1"
# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/__init__.ipynb.

# %% auto 0
__all__ = ['ReconstructionResults', 'ReconstructionOptions', 'ReconstructionInputs', 'reconstruct_mulpty', 'preprocess',
           'build_solver',
           'SolverOptions']

# %% ../nbs/__init__.ipynb 1
from .core import HDF5Dataset as HDF5Dataset
from dataclasses import dataclass
from typing import List, Union
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from .operators.loss import amplitude_loss
import torch as th
from scatterem.util.base import (orthogonalize_probe, shrink_nonneg, apply_butterworth_filter, create_3d_gaussian_kernel,
                                 init_gauss_blur_regularization, gaussian_blur_regularization)
import numpy as np
from torch.utils.data import BatchSampler, SequentialSampler, RandomSampler
from .util.plot import zplot


@dataclass
class ReconstructionResults:
    V: th.Tensor
    probes: List
    positions: List
    losses: th.Tensor


@dataclass
class ReconstructionOptions:
    optimize_probe = lambda it: it > -1
    optimize_sample = lambda it: it > -1
    num_iterations: int = 500
    bin_factor: int = 1
    propagator = lambda it: it
    probe_optimizer = optim.SGD
    object_optimizer = optim.SGD
    probe_optimizer_parameters = {'lr': 30e-3, 'momentum': 0.9}
    object_optimizer_parameters = {'lr': 30e-3, 'momentum': 0.5}
    after_iteration_hooks = []
    after_dataset_hooks = []
    after_batch_hooks = []
    device = None
    batch_size = 1


import torch as th
from torch import nn
from abc import ABC, abstractmethod
from collections.abc import Callable

# complex_2Dobject_forward_model(V, probe, pos, angles, translation, bin_factor, start_end):
# single_slice_patches_model(T_patches, pos, probe, propagator, factor):


from .models import BaseModel


@dataclass
class ReconstructionInputs:
    model: BaseModel
    datasets: List[Dataset]


def reconstruct_mulpty(inputs: ReconstructionInputs, reconstruction_options: ReconstructionOptions):
    opt = reconstruction_options

    model = inputs.model
    datasets = inputs.datasets

    object_optimizer = opt.object_optimizer
    batch_size = opt.batch_size

    sample_optimizer = object_optimizer([model.object], **opt.object_optimizer_parameters)
    # probe_optimizer_list = [[opt.probe_optimizer([probe], **opt.probe_optimizer_parameters)
    #                          for probe in row] for row in model.probe]

    losses = []
    for i in range(opt.num_iterations):
        losses_it = []
        j = 0
        for dataset in datasets:
            # print(f'dataset {j:02d}')
            sampler = BatchSampler(RandomSampler(range(len(dataset))), batch_size=batch_size, drop_last=False)
            pin_memory = str(dataset.data.device) == 'cpu'
            dataloader = DataLoader(dataset, sampler=sampler, batch_sampler=None, batch_size=None,
                                    pin_memory=pin_memory, drop_last=False)

            for batch_index, probe_index, angles_index, r_indices, translation_index, start_end_index, amplitudes_target in dataloader:
                r = model.positions[angles_index][r_indices]
                dr = model.dr[angles_index][r_indices]
                probe_model = model.probe[angles_index][probe_index]
                angle = model.angles[:, angles_index]
                translations = model.translations[translation_index]
                start_end = model.start_end_model[start_end_index]
                amplitudes_target = amplitudes_target.to(r.device)

                # print(f'{j:02d} positions.shape              {r.shape}')
                # print(f'{j:02d} angles.shape                 {angles.shape}')
                # print(f'{j:02d} probe_model.shape            {probe_model.shape}')
                # print(f'{j:02d} amplitudes_target.shape      {amplitudes_target.shape}')
                # print(f'{i:03d} {angles.cpu().numpy()[0]}')

                ## For some reason I can't take probe_optimizer from probe_optimizer_list,
                ## it leads to nans in loss function, but it is better to create all optimizers outside the main loop
                ## cause it saves computing and in general optimizers can have internal memory that we erase building
                ## them inside the loop
                probe_optimizer = opt.probe_optimizer([probe_model], **opt.probe_optimizer_parameters)
                # probe_optimizer = probe_optimizer_list[angles_index][probe_index]

                if opt.optimize_probe(i):
                    probe_model.requires_grad = True
                    probe_optimizer.zero_grad()

                if opt.optimize_sample(i):
                    model.object.requires_grad = True
                    sample_optimizer.zero_grad()

                object_patches = model.object_model(model.object,
                                                    probe_model,
                                                    r,
                                                    angle,
                                                    translations,
                                                    model.bin_factor,
                                                    start_end)
                # if j >= 16 and j <= 19:
                #     amplitudes_model = model.measurement_model(object_patches, r, dr, probe_model, model.propagator2,
                #                                                model.intensity_scaling_factor)
                # else:
                amplitudes_model = model.measurement_model(object_patches, r, dr, probe_model, model.propagator,
                                                           model.intensity_scaling_factor)
                # plotmosaic(np.fft.fftshift(amplitudes_model[:100].detach().cpu().numpy(), (1, 2)), 'amplitudes_model')
                # plotmosaic(np.fft.fftshift((amplitudes_model.detach() - amplitudes_target).cpu().numpy(), (1, 2)), 'amplitudes_model - amplitudes_target')

                loss, loss_per_pattern = model.loss_function(amplitudes_model, amplitudes_target)
                losses_it.append(loss.item())

                # if probe_model.requires_grad:
                #     probe_model.register_hook(lambda grad: print("nan probe grad", th.any(th.isnan(grad))))

                loss.backward()

                if reconstruction_options.optimize_sample(i):
                    model.scale_object_gradient(model.object)
                    # print(th.sum(mode+.object.grad).real)
                    # g = inputs.model.object.grad.cpu().numpy()
                    # print('grad ', g.imag.max())
                    # zplot([g[:,0,:].imag, inputs.model.object[:,0,:].detach().imag.cpu().numpy()], suptitle='V_model gradient',cmap=['inferno', 'inferno'])
                    # g = V_model.grad.cpu().numpy()
                    # print('Max. V_model gradient ', np.abs(g).max())
                    # zplot([g[0].imag, V_model.detach().cpu().numpy()[0].imag], suptitle='V_model gradient',
                    #       cmap=['inferno', 'inferno'])
                    # from scatterem.util.plot import plotAbsAngle
                    # print(f'volume gradient: {th.sum(model.object.grad)}')

                    # model.object = shrink_nonnegative(model.object, model.tau1, model.tau2)
                    sample_optimizer.step()
                    # model.object.real = object_butterworth_constraint(model.object.real, q_lowpass, butterworth_order,
                    #                                                   sampling)
                    # print("model.object")
                    # print(model.object.imag.min())

                    # print(model.object.imag.min())
                    # sample_optimizer.step()
                    # model.object.requires_grad = True
                    # plotAbsAngle(inputs.model.object.detach()[0].sum(1).cpu().numpy(), 'object')

                if reconstruction_options.optimize_probe(i):
                    model.scale_probe_gradient(probe_model)
                    probe_optimizer.step()
                    probe_model = orthogonalize_probe(probe_model, probe_model.device)
                    probe_model.requires_grad = True
                    model.probe[angles_index][probe_index] = probe_model

                for hook in opt.after_batch_hooks:
                    hook(i, model.object, model.probe, model.positions)

            error_norm = model.error_norm[j]
            loss_norm = losses_it[-1] / error_norm
            j += 1
            for hook in opt.after_dataset_hooks:
                hook(i, model.object, model.probe, model.positions)

            if j % 1 == 0:
                # print(f'i {i} loss {losses_ang[-1]:f}')
                print(f'angle {j}  {loss_norm:f}')
                # print(f'angle {j} volume grad: {th.sum(model.object.grad).real}')

        # print(f'angle {np.rad2deg(angle[0].cpu().numpy()):2.2g}')
        losses_it = np.array(losses_it).sum()
        # sample_scheduler.step(losses_it)
        losses.append(losses_it)

        # print("model.object")
        # print(model.object.real.min())

        for hook in opt.after_iteration_hooks:
            hook(i, model.object, model.probe, model.positions)
        if i % 1 == 0:
            print(f'i {i} loss {losses_it.item():2.4g}')
            # print(f'i {i} loss {losses_it_norm:2.4g}')

    results = ReconstructionResults(
        positions=[[r.detach().cpu().numpy() for r in p0] for p0 in inputs.model.positions],
        V=model.object.detach().cpu().numpy(),
        probes=[[p.detach().cpu().numpy() for p in p0] for p0 in inputs.model.probe],
        losses=th.tensor(losses)
    )

    return results


def preprocess(data, metadata):
    return None


def build_solver(preproc_results, solver_options):
    res = None

    def f(data, metadata):
        return 0

    return f


class SolverOptions():
    def __int__(self):
        pass
